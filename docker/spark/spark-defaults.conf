# docker/spark/spark-defaults.conf
# Default Spark configuration for our data pipeline

# Spark application settings
spark.app.name              DataPipelineJob
spark.master                spark://spark-master:7077

# Memory and core settings
spark.executor.memory       2g
spark.executor.cores        2
spark.driver.memory         1g
spark.driver.maxResultSize  1g

# Dynamic allocation (helps with resource efficiency)
spark.dynamicAllocation.enabled     true
spark.dynamicAllocation.minExecutors 1
spark.dynamicAllocation.maxExecutors 4
spark.shuffle.service.enabled       true

# Serialization (Kryo is faster than default Java serialization)
spark.serializer            org.apache.spark.serializer.KryoSerializer
spark.kryo.registrationRequired false

# SQL and DataFrame optimizations
spark.sql.adaptive.enabled  true
spark.sql.adaptive.coalescePartitions.enabled true
spark.sql.adaptive.skewJoin.enabled true
spark.sql.shuffle.partitions 200

# Streaming configuration
spark.streaming.stopGracefullyOnShutdown true
spark.streaming.backpressure.enabled     true
spark.streaming.kafka.maxRatePerPartition 1000

# Network and I/O
spark.network.timeout       120s
spark.rpc.askTimeout        120s

# Checkpoint and logging
spark.checkpoint.compress   true
spark.eventLog.enabled      true
spark.eventLog.dir          /opt/spark/logs

# Compression (reduces network I/O)
spark.io.compression.codec  snappy

# File format defaults
spark.sql.parquet.compression.codec snappy
spark.sql.sources.partitionOverwriteMode dynamic